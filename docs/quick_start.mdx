---
title: Quick Start
description: "Get started with Openmind OS (OM1)"
---

The `Spot` agent uses your webcam to label objects and sends those captions to `OpenAI 4o`. The LLM then returns `movement`, `speech`, and `face` commands, which are displayed in `RacoonSim`. `RacooonSim` also shows basic timing and other debug information.

**NOTE**: The simulator shows you generated speech, but does not send anything to your computer's audio hardware, reducing the need for you to install audio drivers.

1. Clone the repo

```bash clone repo
git clone https://github.com/OpenmindAGI/OM1.git
cd OM1
git submodule update --init
uv venv
```

Note: If you don't have the Rust python package manager `uv`, please install it via `brew install uv` (for Mac) and `curl -LsSf https://astral.sh/uv/install.sh | sh` for Linux.

2. Set configuration variables

Add your Openmind API key in `/config/spot.json`. You can obtain a free access key at https://portal.openmind.org/. If you use the placeholder, `openmind-free`, you may be rate limited.

```bash set api key
# /config/spot.json`
...
"api_key": "openmind_om1_pat_2f1cf005af........."
...
```

3. Run Spot, a `Hello World` agent

```bash run spot
uv run src/run.py spot
```

Add `--debug` to see more logging information.

<Tip>`uv` does many things in the background, such as setting up a `venv` and downloading any dependencies if needed. Please add new dependencies to `pyproject.toml`.</Tip>

<Note>If you are running complex models, or need to download dependencies, there may be a delay before the agent starts.</Note>
