---
title: LLM Models
description: "Using Gemini and other models as the Core LLM"
---

These examples are similar to the `Hello World (Spot)` example, except they use `DeepSeek` or `Gemini` rather than `OpenAI 4o`.

```bash LLM Models
uv run src/run.py deepseek
uv run src/run.py gemini
```

You can directly access other OpenAI style endpoints by specifying a custom API endpoint in your configuration file. To do this, provide an suitable `base_url` and the `api_key` for OpenAI, DeepSeek, or other providers. Possible `base_url` choices are:
* https://api.openai.com/v1
* https://api.deepseek.com/v1
* https://generativelanguage.googleapis.com/v1beta/openai/
* and many others...